---
title: "Sprawozdanie 2"
author: "Krzysztof Kotlarz"
date: "24.03.2020"
output:
  pdf_document: 
    highlight: haddock
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r include=FALSE}
dane <- read.table('http://theta.edu.pl/wp-content/uploads/2018/03/dane_kosiarki-1.txt', header = TRUE)
head(dane)
attach(dane)
library(MASS)
```



# Lista 3

## Zadanie 5

### (i)

```{r echo=FALSE}
model.1 <- lda(owner~income + lotsize, data = dane)
model.1
```

Średnie w poszczególnych grupach kształtują sie następująco:

* dla grupy *1* *income* = 26.49, *lotsize* = 10.13
* dla grupy *2* *income* = 19.13, *lotsize* = 8.82

### (ii)

Wartości współczynników klasyfikacyjnych są następujące:

* $LD1 = -0.1453 * income -0.759 * lotsize$

### (iii)

Im większy współczynnik zmiennej tym jest on istotniejszy: większy współczynnik znajduje się przy zmiennej *income*

### (iV)

```{r}
LD1 <- predict(model.1)$x
sum(LD1 * (dane$owner == 1)) / sum(dane$owner == 1)
sum(LD1 * (dane$owner == 2)) / sum(dane$owner == 2)
```


Średnie wartości funkcji dyskryminacyjnych dla:

* *owner = 1*: -1.034
* *owner  = 2*: 1.034

### (v)

```{r}
owner.predict <- predict(model.1, dane[,1:2])
```

Za zbiór testowy przyjmujemy cały zbiór danych

### (vi)

```{r}
owner.predict$posterior[20,]
```

Prawdopodobieństwo przynależności obserwacji 20 dla poszczególnych grup:

* grupa *1*: 0.016
* grupa *2*: 0.984

### (vii)

Ta obserwacja zostanie zaklasyfikowana do grupy 2 z prawdopodobieństwem 98.4%

### (xiii)

```{r}
owner.classes <- owner.predict$class
sum(owner.classes==owner)/length(owner)   
```
Poprawana klasyfikacji 87.5% obserwacji

### (ix)

```{r echo=FALSE}
table(Original = dane$owner, Predicted =predict(model.1)$class)
```

Coefficient matrix przedstawia w wierszach przynależność obserwacji do klas ze zbioru, natomiast kolumny przynależność obserwacji do klas przewidziane przez model:

* 11 obserwacji bedących *owner* = 1, zostało poprawnie przewidziane przez model, natomiast 1 obserwacja błędnie

* 10 obserwacji bedących *owner* = 2, zostało poprawnie przewidziane przez model, natomiast 2 obserwacje błednie 

## Zadnie 6.

# (i)

```{r include=FALSE}
library(tidyverse)

dane2 <- read.table('http://theta.edu.pl/wp-content/uploads/2018/03/dane_wino.txt', sep = ',')
attach(dane2)

dane2 <- rename(dane2, t_uprawy=V1)

dane2$t_uprawy <- as.character(dane2$t_uprawy)

model.2 <- lda(t_uprawy ~ ., data = dane2)
```


```{r echo=FALSE}
model.2
```

### (i)
Średnie w grupach prezentują się następująco:

```{r}
knitr::kable(model.2$means, caption = 'Średnie wartości w grupach', digits = 3, row.names = c(1,2,3,4))
```

### (ii)

Współczynniki dla poszczególnych zmiennych są następujące:

```{r}
knitr::kable(model.2$scaling, digits = 3)
```

### (iii)

Im większy współczynnik zmiennej tym jest on istotniejszy: 

* dla LD1 najbardziej istotna zmienna: *V7* (0.618)

* dla LD2 najbardziej istotna zmienna: *V4* (2.346)

### (iv)


```{r echo=FALSE}
LD1 <- predict(model.2)$x[,1]

LD2 <- predict(model.2)$x[,2]

plot(LD1, LD2, xlab = " Pierwsza zmienna kanoniczna ", ylab = " Druga zmienna
kanoniczna ", type ="n" )
text (cbind (LD1, LD2 ), labels = unclass(dane2$t_uprawy))
```


```{r}
sum(LD1 * (dane2$t_uprawy == 1)) / sum(dane2$t_uprawy == 1)
```
```{r}
sum(LD2 * (dane2$t_uprawy == 1)) / sum(dane2$t_uprawy == 1)
```

```{r}
sum(LD1 * (dane2$t_uprawy == 2)) / sum(dane2$t_uprawy == 2)
```

```{r}
sum(LD2 * (dane2$t_uprawy == 2)) / sum(dane2$t_uprawy == 2)
```

```{r}
sum(LD1 * (dane2$t_uprawy == 3)) / sum(dane2$t_uprawy == 3)
```

```{r}
sum(LD2 * (dane2$t_uprawy == 3)) / sum(dane2$t_uprawy == 3)
```


Średnie wartości funkcji dyskryminacyjnych dla:

* *t_uprawy* = 1:
  + *LD1*: -3.422
  + *LD2*: 1.691

* *t_uprawy* = 2:
  + *LD1*: -0.079
  + *LD2*: -2.472

* *t_uprawy* = 3:
  + *LD1*: 4.324
  + *LD2*: 1.578
  
### (v)

```{r}
type_u.predict <- predict(model.2, dane2[,2:14])
```

Za zbiór testowy przyjmujemy cały zbiór danych

### (vi)

```{r}
type_u.predict$posterior[20,]
```

Prawdopodobieństwo przynależności obserwacji 20 dla poszczególnych grup:

* grupa 1: 0.99

* grupa 2: 6.13e-07

* grupa 3 : 6.64e-13

### (vii)

Obserwacja zostanie zaklasyfikowana do grupy 1 z prawdopdoobienstwem 99%

### (viii)

```{r}
type_u.classes <- type_u.predict$class
type_u.classperc <- sum(type_u.classes==dane2$t_uprawy)/length(dane2$t_uprawy)
type_u.classperc
```

Poprawana klasyfikacji 100% obserwacji

### (ix)

```{r}
table(Original = dane2$t_uprawy, Predicted = predict(model.2)$class)
```
Coefficient matrix przedstawia w wierszach przynależność obserwacji do klas ze zbioru, natomiast kolumny przynależność obserwacji do klas przewidziane przez model:

* Wszystkie obserwacje zostały poprawnie zaklasyfikowane do odpowiednich grup

# Lista 4

## Zadanie 7

```{r}
dane <- read.csv('http://theta.edu.pl/wp-content/uploads/2018/03/urine.csv', skip = 1, dec= '.', sep = ',', col.names = c('id','r','gravity','ph','osmo','cond','urea','calc'))
dane <- dane[,2:8]
```

```{r}
dane$r <- as.factor(dane$r)
dane <- na.omit(dane)
```

### (i)

```{r}
set.seed(123)

train_ind <- sample(seq_len(nrow(dane)), size = 50)

train <- dane[train_ind, ]
test <- dane[-train_ind, ]
```

### (ii)

```{r}
model.glm <- glm(r ~ . , data = train, family = binomial)
summary(model.glm)
```

### (iii)

```{r}
model.glm.1 <- glm(r~. -gravity, data = train, family = binomial)
summary(model.glm.1)
```

Usunięto nieistotną zmienna *gravity*

```{r}
model.glm.2 <- glm(r~. -gravity -ph, data = train, family = binomial)
summary(model.glm.2)
```

Usunięto nieistotną zmienna *ph*

### (iV)

```{r}
predictGLM <- predict(model.glm.2, newdata = train)
plot(predictGLM, pch = as.numeric(dane$r) + 1, ylab = 'Logit prawdopodobieństwa', main = 'Logity prawdopodobieństwa dla zbioru treningowego')
```

```{r}
predictLR <- predict(model.glm.2, newdata = test)
plot(predictLR, pch = as.numeric(dane$r) + 1, ylab = 'Logit prawdopodobieństwa', main = 'Logity prawdopodobieństwa dla zbioru testowego')
```

```{r}

TAB <- table(test[,1], predictLR > 0)
knitr::kable(TAB)
```

Coefficient matrix przedstawia w wierszach przynależność obserwacji do klas ze zbioru, natomiast kolumny przynależność obserwacji do klas przewidziane przez model:

* 13 obserwacji bedących *r* = 0, zostało poprawnie przewidziane przez model, natomiast 2 obserwacja błędnie

* 7 obserwacji bedących *r* = 1, zostało poprawnie przewidziane przez model, natomiast 5 obserwacje błednie 

```{r}
mcrlr <- 1-sum(diag(TAB))/sum(TAB)
mcrlr
```
Błąd klasyfikacji wynosi 25.9%

### (v)
```{r include=FALSE}
library(MASS)
```

```{r}
model.lda <- lda(r~. -gravity -ph, data = train)
model.lda
```

```{r}
lda.predict <- predict(model.lda, test[ ,2:7])
pid.classperc <- sum(lda.predict$class == test[ ,1]) / nrow(test)
pid.classperc
```

```{r}
1 - pid.classperc
```

Bład klasyfikacji w przypadku regresji logistycznej jak i metody LDA jest taki sam (25.9%).

## Zadanie 8

```{r}
dane3 <- read.table('http://theta.edu.pl/wp-content/uploads/2018/03/puls2.csv', header = TRUE, sep = ';')

attach(dane3)

dane3$Palacz <- as.factor(dane3$Palacz)
```

### (i)

```{r}
set.seed(333)

smp_size <- floor(0.75 * nrow(dane3))

train_ind <- sample(seq_len(nrow(dane3)), size = smp_size)

train <- dane3[train_ind, ]
test <- dane3[-train_ind, ]
```

### (ii)

```{r}
model.4 <- glm(TetnoSpocz~Palacz+Waga, data = train, family = binomial)
summary(model.4)
```

### (iii)

```{r}
model.5 <- glm(TetnoSpocz~Waga, data = train, family = binomial)
summary(model.5)
```

Usunięto nieistotną zmienna *Palacz*. Ostatecznie w modelu pozostaje zmienna *Waga*

### (iv)

```{r}
model.m1 <- glm(TetnoSpocz~Palacz*Waga, data = train, family = binomial)
summary(model.m1)
```

Nieistotna zmienna *Palacz* oraz interakcja pomiedzy zmiennymi *Palacz* i *Waga*

### (v)

```{r}
model.m2 <- glm(TetnoSpocz~Waga + Palacz:Waga, data = train, family = binomial)
summary(model.m2)
```

```{r}
model.m3 <- glm(TetnoSpocz~ Palacz + Palacz:Waga, data = train, family = binomial)
summary(model.m3)
```

```{r}
model.m4 <- glm(TetnoSpocz~Palacz:Waga, data = train, family = binomial)
summary(model.m4)
```

Model **M4** zawiera zmienne istotne: jest to model uwzględniający tylko interakcje pomiedzy zmiennymi *Palacz* i *Waga*

#### Dla pełnego modelu

```{r}
predictGLM <- predict(model.4, newdata = train)
plot(predictGLM, pch = as.numeric(dane3$TetnoSpocz))
```

```{r}
predictLR <- predict(model.4, newdata = test)
TAB <- table(test[,1], predictLR > 0)
knitr::kable(TAB)
```

* 17 obserwacji bedących *TetnoSpocz* = Niskie, zostało poprawnie przewidziane przez model, natomiast 0 obserwacja błędnie

* 2 obserwacji bedących *TetnoSpocz* = Wysokie, zostało poprawnie przewidziane przez model, natomiast 4 obserwacje błednie 

```{r}
mcrlr <- 1-sum(diag(TAB))/sum(TAB)
mcrlr
```

Błąd klasyfikacji dla pełnego modelu wynosi 17.4%

#### Dla M4
```{r}
predictGLMM4 <- predict(model.m4, newdata = train)
plot(predictGLMM4, pch = as.numeric(dane3$TetnoSpocz))
```

```{r}
predictLRM4 <- predict(model.m4, newdata = test)
TABM4 <- table(test[,1], predictLRM4 > 0)
knitr::kable(TABM4)
```

* 17 obserwacji bedących *TetnoSpocz* = Niskie, zostało poprawnie przewidziane przez model, natomiast 0 obserwacja błędnie

* 2 obserwacji bedących *TetnoSpocz* = Wysokie, zostało poprawnie przewidziane przez model, natomiast 4 obserwacje błednie 

```{r}
mcrlr <- 1-sum(diag(TABM4))/sum(TABM4)
mcrlr
```

Błąd klasyfikacji w przypadku regresji logistycznej wynosi dla obu modeli (pełny i M4) 17.4%

```{r}
library(MASS)
model.lda <- lda(TetnoSpocz~Palacz + Waga, data = train)
model.lda
```

```{r}
lda.predict <- predict(model.lda, test[ ,2:3])
pid.classperc <- sum(lda.predict$class == test[ ,1]) / nrow(test)
pid.classperc
```

```{r}
1 - pid.classperc
```

W celu porównania obu klasyfikacji, w modelu LDA użyto tych samych zmiennych co w modelu regresji logistycznejBład klasyfikacji w przypadku regresji logistycznej jak i metody LDA jest taki sam (17.4%).






  
  
  
  
  
  
  
  
  
  
  